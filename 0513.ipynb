{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3fcd92-3b2e-4d73-9332-6d638be1bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "df=pd.read_csv('diabetes.csv',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe5145-712c-4687-ad4b-7315ceabebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=pd.read_csv('PAMAP_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92bf93b-d29c-43ed-8eb7-6160a5e79314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046d25fa-4939-459f-9ab6-05a903c34a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 1, 9, 10, 11, 12, 13, 2, 14, 15, 3, 16, 2, 17, 18, 19, 20, 21, 22, 4, 5, 1, 23, 6, 24, 4, 5, 1, 25, 6, 26, 3, 27, 28, 29, 30, 1, 31]\n",
      "{'the': 1, 'a': 2, 'hope': 3, 'wait': 4, 'till': 5, 'is': 6, 'soft': 7, 'as': 8, 'voice': 9, 'of': 10, 'an': 11, 'angel': 12, 'breathing': 13, 'lesson': 14, 'unhead': 15, 'with': 16, 'gentle': 17, 'persuasion': 18, 'whispers': 19, 'her': 20, 'comforting': 21, 'word': 22, 'darkness': 23, 'over': 24, 'tempest': 25, 'done': 26, 'for': 27, 'sunshine': 28, 'tomorrow': 29, 'after': 30, 'shower': 31}\n",
      "어휘 크기: 32\n",
      "[[7, 8], [8, 1], [1, 9], [9, 10], [10, 11], [11, 12], [12, 13], [13, 2], [2, 14], [14, 15], [15, 3], [3, 16], [16, 2], [2, 17], [17, 18], [18, 19], [19, 20], [20, 21], [21, 22], [22, 4], [4, 5], [5, 1], [1, 23], [23, 6], [6, 24], [24, 4], [4, 5], [5, 1], [1, 25], [25, 6], [6, 26], [26, 3], [3, 27], [27, 28], [28, 29], [29, 30], [30, 1], [1, 31]]\n",
      "총 시퀀스 개수: 38\n",
      "X= [ 7  8  1  9 10 11 12 13  2 14 15  3 16  2 17 18 19 20 21 22  4  5  1 23\n",
      "  6 24  4  5  1 25  6 26  3 27 28 29 30  1]\n",
      "y= [ 8  1  9 10 11 12 13  2 14 15  3 16  2 17 18 19 20 21 22  4  5  1 23  6\n",
      " 24  4  5  1 25  6 26  3 27 28 29 30  1 31]\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                1650      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2171 (8.48 KB)\n",
      "Trainable params: 2171 (8.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "text_data=\"\"\"Soft as the voice of an angel\\n\n",
    "Breathing a lesson unhead\\n\n",
    "Hope with a gentle persuasion\\n\n",
    "Whispers her comforting word\\n\n",
    "Wait till the darkness is over\\n\n",
    "Wait till the tempest is done\\n\n",
    "Hope for sunshine tomorrow\\n\n",
    "After the shower\"\"\"\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text_data])\n",
    "encoded = tokenizer.texts_to_sequences([text_data])[0]\n",
    "print(encoded)\n",
    "print(tokenizer.word_index)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('어휘 크기: %d' % vocab_size)\n",
    "sequences = list()\n",
    "for i in range(1, len(encoded)):\n",
    "\tsequence = encoded[i-1:i+1]\n",
    "\tsequences.append(sequence)\n",
    "print(sequences)\n",
    "print('총 시퀀스 개수: %d' % len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,0],sequences[:,1]\n",
    "print(\"X=\", X)\n",
    "print(\"y=\", y)\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LSTM, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping=EarlyStopping(patience=5)\n",
    "inputs = Input(shape=(vocab_size,))\n",
    "layer1 = Dense(50, activation='relu')(inputs)\n",
    "layer2 = Dense(10, activation='relu')(layer1)\n",
    "outputs = Dense(1, activation='softmax')(layer2)\n",
    "model = Model(inputs=inputs, outputs= outputs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae82a444-72e1-4369-bfbb-b16cd3c9aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_3' (type Functional).\n    \n    Input 0 of layer \"dense_9\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'model_3' (type Functional):\n      • inputs=tf.Tensor(shape=(None,), dtype=int32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, callbacks \u001b[38;5;241m=\u001b[39m [early_stopping])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filejxxpl_2f.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_3' (type Functional).\n    \n    Input 0 of layer \"dense_9\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'model_3' (type Functional):\n      • inputs=tf.Tensor(shape=(None,), dtype=int32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=1000, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f26bbf5-5b7e-4c19-98c5-90a55e1781c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_2' (type Functional).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'model_2' (type Functional):\n      • inputs=tf.Tensor(shape=(None,), dtype=int32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m encoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(encoded)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 신경망의 예측값을 출력해본다. \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m onehot_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(encoded)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monehot_output=\u001b[39m\u001b[38;5;124m'\u001b[39m, onehot_output)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 가장 높은 출력을 내는 유닛을 찾는다. \u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileyoe3muuh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\alsgu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_2' (type Functional).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'model_2' (type Functional):\n      • inputs=tf.Tensor(shape=(None,), dtype=int32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_text = 'Wait'\n",
    "encoded = tokenizer.texts_to_sequences([test_text])[0]\n",
    "encoded = np.array(encoded)\n",
    "\n",
    "# 신경망의 예측값을 출력해본다. \n",
    "onehot_output = model.predict(encoded)\n",
    "print('onehot_output=', onehot_output)\n",
    "\n",
    "# 가장 높은 출력을 내는 유닛을 찾는다. \n",
    "output = np.argmax(onehot_output)\n",
    "print('output=', output)\n",
    "\n",
    "# 출력층의 유닛 번호를 단어로 바꾼다. \n",
    "print(test_text, \"=>\", end=\" \")\n",
    "for word, index in tokenizer.word_index.items():\n",
    "\tif index == output:\n",
    "\t\tprint(word)\n",
    "#249p UCI SEED 분류, 함수혈, dropout, whrlehghy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11956e6-d77d-4541-8df5-aa987d5c040a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
