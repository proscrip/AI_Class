{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f7bdd5-7422-4d26-b6a5-34fd7d7dbe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 64)           640000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                409664    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1049729 (4.00 MB)\n",
      "Trainable params: 1049729 (4.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4556 - accuracy: 0.7717 - val_loss: 0.3353 - val_accuracy: 0.8528\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1659 - accuracy: 0.9402 - val_loss: 0.4032 - val_accuracy: 0.8345\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 0.5215 - val_accuracy: 0.8376\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.6024 - val_accuracy: 0.8401\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.8396\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 8.8596e-04 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8412\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 5.3593e-04 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8415\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 3.7293e-04 - accuracy: 1.0000 - val_loss: 0.7412 - val_accuracy: 0.8422\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 2.5131e-04 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.8428\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 1.8067e-04 - accuracy: 1.0000 - val_loss: 0.7954 - val_accuracy: 0.8427\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 1.4906e-04 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.8433\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 1.1481e-04 - accuracy: 1.0000 - val_loss: 0.8412 - val_accuracy: 0.8431\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 8.5632e-05 - accuracy: 1.0000 - val_loss: 0.8627 - val_accuracy: 0.8424\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 7.0519e-05 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.8429\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.0041 - val_accuracy: 0.8065\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.9486 - val_accuracy: 0.8184\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 1.0634 - val_accuracy: 0.8200\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 5.1709e-04 - accuracy: 1.0000 - val_loss: 1.1072 - val_accuracy: 0.8214\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 2.8605e-04 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.8229\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 1.5525e-04 - accuracy: 1.0000 - val_loss: 1.1814 - val_accuracy: 0.8236\n",
      "782/782 - 1s - loss: 1.1814 - accuracy: 0.8236 - 677ms/epoch - 866us/step\n",
      "[1.1814045906066895, 0.823639988899231]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "부정적인 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "imdb = keras.datasets.imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "print(x_train[0])\n",
    "word_to_index = imdb.get_word_index()\n",
    "\n",
    "# 처음 몇 개의 인덱스는 특수 용도로 사용된다. \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "word_to_index[\"<PAD>\"] = 0\t\t# 문장을 채우는 기호\n",
    "word_to_index[\"<START>\"] = 1\t\t# 시작을 표시\n",
    "word_to_index[\"<UNK>\"] = 2  \t\t# 알려지지 않은 토큰 \n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=100)\n",
    "x_test = pad_sequences(x_test, maxlen=100)\n",
    "\n",
    "vocab_size = 10000\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64,\n",
    "                    input_length=100))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=20, verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "results = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(results)\n",
    "review = \"this is never 1 point. It's my desire to give 11 point.\"#\"What can I say about this movie that was already said? It is my favorite time travel sci-fi, adventure epic comedy in the 80's and I love this movie to death! When I saw this movie I was thrown out by its theme. An excellent sci-fi, adventure epic, I LOVE the 80s. It's simple the greatest time travel movie ever happened in the history of world cinema. I love this movie to death, I love, LOVE, love it!\"\n",
    "import re\n",
    "review = re.sub(\"[^0-9a-zA-Z ]\", \"\", review).lower()\n",
    "\n",
    "review_encoding = []\n",
    "# 리뷰의 각 단어 대하여 반복한다. \n",
    "for w in review.split():\n",
    "\t\tindex = word_to_index.get(w, 2)\t# 딕셔너리에 없으면 2 반환\n",
    "\t\tif index <= 10000:\t\t# 단어의 개수는 10000이하\n",
    "\t\t\treview_encoding.append(index)\n",
    "\t\telse:\n",
    "\t\t\treview_encoding.append(word_to_index[\"UNK\"])\n",
    "\n",
    "# 2차원 리스트로 전달하여야 한다. \n",
    "test_input = pad_sequences([review_encoding], maxlen = 100) \n",
    "value = model.predict(test_input) # 예측\n",
    "if(value > 0.5):\n",
    "\tprint(\"긍정적인 리뷰입니다.\")\n",
    "else:\n",
    "\tprint(\"부정적인 리뷰입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35404326-d9a4-4c75-bd59-5ee1b9cb83da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
